{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fd5595bf67ff0d81a45cc3bd4fb9c8522eed4bcc14c71b1d1dd93f694c8cf4a8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "># Impoting libs for the preprocess the data an train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "># Importing both datasets, the Housig prices and test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "X_full = pd.read_csv('Housing_prices.csv',index_col='Id')\n",
    "X_test_full = pd.read_csv('Housing_prices_test.csv', index_col='Id')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 50,
   "outputs": []
  },
  {
   "source": [
    "># Removing rows with missing target from full data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.dropna(axis=0, subset= ['SalePrice'], inplace= True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis= 1, inplace= True)"
   ]
  },
  {
   "source": [
    "># Separating test and training the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, train_size=0.8, test_size= 0.2, random_state=0)"
   ]
  },
  {
   "source": [
    "># Selecting categorical columns with low cardinality values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [col_name for col_name in X_train_full.columns if X_train_full[col_name].nunique() < 10 and X_train_full[col_name].dtype == 'object']"
   ]
  },
  {
   "source": [
    "># Selecting numerical columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [col_name for col_name in X_train_full.columns if X_train_full[col_name].dtype in ['int64','float64']]"
   ]
  },
  {
   "source": [
    "># Keeping the selected columns only making a copy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "source": [
    "X_train.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 : Improving the performance\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer (strategy= 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for the categorical data\n",
    "categorical_transformer = Pipeline(steps= [\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown= 'ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle both preprocessing from categorical and numerical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "('numerical', numerical_transformer, numerical_cols),\n",
    "('categorical', categorical_transformer,categorical_cols)        \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "model = RandomForestRegressor(n_estimators=500, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle the preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data and fit model\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "# Preprocessing of validation data and get predictions\n",
    "predictions = my_pipeline.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Generating test predictions\r\n",
    "# Preprocessing of test data and fit model\r\n",
    "predictions_test = my_pipeline.predict(X_test)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': predictions_test})\n",
    "output.to_csv('predictions.csv', index=False)"
   ]
  }
 ]
}